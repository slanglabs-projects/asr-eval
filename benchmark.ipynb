{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f21fad",
   "metadata": {},
   "source": [
    "# Benchmark report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa09680",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c7eecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def make_bold(txt):\n",
    "    return f'\\033[1m{txt}\\033[0m'\n",
    "\n",
    "def gen_results(dataframe, cohort=None):\n",
    "    engines = [\"indic_conformer\", \"google_speech\", \"slang_google_speech\"]\n",
    "    \n",
    "    _df = pd.DataFrame(data={})\n",
    "    \n",
    "    wer = []\n",
    "    intent_metrics = []\n",
    "    entity_metrics = []\n",
    "    \n",
    "    for engine in engines:\n",
    "        #print(f'{make_bold(engine+\":\")} {dataframe[engine+\"_wer\"].mean()}')\n",
    "        wer.append(dataframe[engine+\"_wer\"].mean())\n",
    "    \n",
    "        \n",
    "    #print(\"--\"*25+\"\\n\")\n",
    "    \n",
    "    for engine in engines:\n",
    "        with open(f'intent_metrics_{engine}_{cohort}.json', 'r') as i:\n",
    "            _intent_metrics = json.load(i)\n",
    "            #print(f'{make_bold(engine+\" intent f1-score: \")} {intent_metrics[\"weighted avg\"][\"f1-score\"]}')\n",
    "            intent_metrics.append(_intent_metrics[\"weighted avg\"][\"f1-score\"])\n",
    "    \n",
    "    #print(\"--\"*25+\"\\n\")\n",
    "    \n",
    "    for engine in engines:\n",
    "        with open(f'entity_metrics_{engine}_{cohort}.json', 'r') as e:\n",
    "            _entity_metrics = json.load(e)\n",
    "            #print(f'{make_bold(engine+\" entity f1-score: \")} {entity_metrics[\"f1\"]}')\n",
    "            entity_metrics.append(_entity_metrics[\"f1\"])\n",
    "            \n",
    "    _df[\"Engines\"] = engines\n",
    "    _df[\"Word Error Rate (WER)\"] = wer\n",
    "    _df[\"Intent Accuracy (IA)\"] = intent_metrics\n",
    "    _df[\"Entity Accuracy (E\"] = entity_metrics\n",
    "    \n",
    "    return _df\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386550b8",
   "metadata": {},
   "source": [
    "## Raw transcription + Slang Normalizer comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "580efe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>WER</th>\n",
       "      <th>Intent Metrics</th>\n",
       "      <th>Entity Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.259178</td>\n",
       "      <td>0.697644</td>\n",
       "      <td>0.551685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.161722</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.639110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.161433</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.639110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines       WER  Intent Metrics  Entity Metrics\n",
       "0      indic_conformer  0.259178        0.697644        0.551685\n",
       "1        google_speech  0.161722        0.731920        0.639110\n",
       "2  slang_google_speech  0.161433        0.731920        0.639110"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ASR_quality_metrics_1.csv')\n",
    "\n",
    "gen_results(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00afe989",
   "metadata": {},
   "source": [
    "## Slang Normalizer + NeMo comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dbe607e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>WER</th>\n",
       "      <th>Intent Metrics</th>\n",
       "      <th>Entity Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.308179</td>\n",
       "      <td>0.724729</td>\n",
       "      <td>0.571271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.638771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.636943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines       WER  Intent Metrics  Entity Metrics\n",
       "0      indic_conformer  0.308179        0.724729        0.571271\n",
       "1        google_speech  0.164870        0.731920        0.638771\n",
       "2  slang_google_speech  0.163579        0.731920        0.636943"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('ASR_quality_metrics_2.csv')\n",
    "\n",
    "gen_results(df2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acbd58",
   "metadata": {},
   "source": [
    "## Slang Normalizer + Number Parser comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e9a0d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>WER</th>\n",
       "      <th>Intent Metrics</th>\n",
       "      <th>Entity Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.302173</td>\n",
       "      <td>0.713823</td>\n",
       "      <td>0.579151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.161598</td>\n",
       "      <td>0.734378</td>\n",
       "      <td>0.644786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.161309</td>\n",
       "      <td>0.734378</td>\n",
       "      <td>0.644786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines       WER  Intent Metrics  Entity Metrics\n",
       "0      indic_conformer  0.302173        0.713823        0.579151\n",
       "1        google_speech  0.161598        0.734378        0.644786\n",
       "2  slang_google_speech  0.161309        0.734378        0.644786"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('ASR_quality_metrics_3.csv')\n",
    "\n",
    "gen_results(df3, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
