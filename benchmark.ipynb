{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f21fad",
   "metadata": {},
   "source": [
    "# Benchmark report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa09680",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7eecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def make_bold(txt):\n",
    "    return f'\\033[1m{txt}\\033[0m'\n",
    "\n",
    "def gen_results(dataframe, cohort=None):\n",
    "    engines = [\"indic_conformer\", \"google_speech\", \"slang_google_speech\"]\n",
    "    \n",
    "    _df = pd.DataFrame(data={})\n",
    "    \n",
    "    wer = []\n",
    "    intent_metrics = []\n",
    "    entity_metrics = []\n",
    "    \n",
    "    for engine in engines:\n",
    "        #print(f'{make_bold(engine+\":\")} {dataframe[engine+\"_wer\"].mean()}')\n",
    "        wer.append(dataframe[engine+\"_wer\"].mean())\n",
    "    \n",
    "        \n",
    "    #print(\"--\"*25+\"\\n\")\n",
    "    \n",
    "    for engine in engines:\n",
    "        with open(f'data/intent_metrics_{engine}_{cohort}.json', 'r') as i:\n",
    "            _intent_metrics = json.load(i)\n",
    "            #print(f'{make_bold(engine+\" intent f1-score: \")} {intent_metrics[\"weighted avg\"][\"f1-score\"]}')\n",
    "            intent_metrics.append(_intent_metrics[\"weighted avg\"][\"f1-score\"])\n",
    "    \n",
    "    #print(\"--\"*25+\"\\n\")\n",
    "    \n",
    "    for engine in engines:\n",
    "        with open(f'data/entity_metrics_{engine}_{cohort}.json', 'r') as e:\n",
    "            _entity_metrics = json.load(e)\n",
    "            #print(f'{make_bold(engine+\" entity f1-score: \")} {entity_metrics[\"f1\"]}')\n",
    "            entity_metrics.append(_entity_metrics[\"f1\"])\n",
    "            \n",
    "    _df[\"Engines\"] = engines\n",
    "    _df[\"Word Error Rate (WER)\"] = wer\n",
    "    _df[\"Intent Accuracy (IA)\"] = intent_metrics\n",
    "    _df[\"Entity Accuracy (E\"] = entity_metrics\n",
    "    \n",
    "    return _df\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386550b8",
   "metadata": {},
   "source": [
    "## Raw transcription + Slang Normalizer comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580efe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>Word Error Rate (WER)</th>\n",
       "      <th>Intent Accuracy (IA)</th>\n",
       "      <th>Entity Accuracy (E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.259178</td>\n",
       "      <td>0.697644</td>\n",
       "      <td>0.551685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.161722</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.639110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.161433</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.639110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines  Word Error Rate (WER)  Intent Accuracy (IA)  \\\n",
       "0      indic_conformer               0.259178              0.697644   \n",
       "1        google_speech               0.161722              0.731920   \n",
       "2  slang_google_speech               0.161433              0.731920   \n",
       "\n",
       "   Entity Accuracy (E  \n",
       "0            0.551685  \n",
       "1            0.639110  \n",
       "2            0.639110  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ASR_quality_metrics_1.csv')\n",
    "\n",
    "gen_results(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00afe989",
   "metadata": {},
   "source": [
    "## Slang Normalizer + NeMo comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe607e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>Word Error Rate (WER)</th>\n",
       "      <th>Intent Accuracy (IA)</th>\n",
       "      <th>Entity Accuracy (E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.308179</td>\n",
       "      <td>0.724729</td>\n",
       "      <td>0.571271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.638771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.731920</td>\n",
       "      <td>0.636943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines  Word Error Rate (WER)  Intent Accuracy (IA)  \\\n",
       "0      indic_conformer               0.308179              0.724729   \n",
       "1        google_speech               0.164870              0.731920   \n",
       "2  slang_google_speech               0.163579              0.731920   \n",
       "\n",
       "   Entity Accuracy (E  \n",
       "0            0.571271  \n",
       "1            0.638771  \n",
       "2            0.636943  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/ASR_quality_metrics_2.csv')\n",
    "\n",
    "gen_results(df2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acbd58",
   "metadata": {},
   "source": [
    "## Slang Normalizer + Number Parser comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e9a0d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engines</th>\n",
       "      <th>Word Error Rate (WER)</th>\n",
       "      <th>Intent Accuracy (IA)</th>\n",
       "      <th>Entity Accuracy (E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indic_conformer</td>\n",
       "      <td>0.302173</td>\n",
       "      <td>0.713823</td>\n",
       "      <td>0.579151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google_speech</td>\n",
       "      <td>0.161598</td>\n",
       "      <td>0.734378</td>\n",
       "      <td>0.644786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slang_google_speech</td>\n",
       "      <td>0.161309</td>\n",
       "      <td>0.734378</td>\n",
       "      <td>0.644786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Engines  Word Error Rate (WER)  Intent Accuracy (IA)  \\\n",
       "0      indic_conformer               0.302173              0.713823   \n",
       "1        google_speech               0.161598              0.734378   \n",
       "2  slang_google_speech               0.161309              0.734378   \n",
       "\n",
       "   Entity Accuracy (E  \n",
       "0            0.579151  \n",
       "1            0.644786  \n",
       "2            0.644786  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('data/ASR_quality_metrics_3.csv')\n",
    "\n",
    "gen_results(df3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c916b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325d2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
